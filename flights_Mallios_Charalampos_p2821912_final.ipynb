{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flights Data Set\n",
    "\n",
    "\n",
    "> Mallios Charalampos, Student - p2821912 <br />\n",
    "> Department of Management Science and Technology <br />\n",
    "> Msc Business Analytics <br />\n",
    "> Athens University of Economics and Business <br />\n",
    "> p2821912@aueb.gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "\n",
    "## Task 1\n",
    "Provide a \"misery index\" for airports. That is, sort the airports in descending order of the probability that a flight departing from that airport has a delay. Take care of outliers: some airports may have a preposterously low number of flights. We are not interested in them. Your criterion for outliers will be the airports in the lowest 1% percentile in the number of flights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First we have to initialize connection with Spark and create an APP named \"Spark assignement\".\n",
    "* The next step is to read the corrensponding csv as Spark dataframe.\n",
    "* Compute the number of flights for each ORIGIN and store into a dataframe. \n",
    "* Compute the outliers, every observation <= 58 will be dropped out.\n",
    "* Find the number of delayed flights(those have departure_time >0) and stored into a dataframe.\n",
    "* Join together the previous dataframes ( all flights - delayed flights) into a new dataframe.\n",
    "* Compute measury index as new column into the joined dataframe created above(all flights / delayed flights).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#we create Spark session\n",
    "spark =  SparkSession.builder.appName(\"Spark assignement\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark assignement</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11b84ed68>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark # check if is it initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "#read the corresponding csv input file along with the headers\n",
    "\n",
    "flights = spark\\\n",
    "  .read\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .csv(\"515364771_T_ONTIME_REPORTING.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|ORIGIN|Number of flights|\n",
      "+------+-----------------+\n",
      "|   YNG|                2|\n",
      "|   ART|               25|\n",
      "|   IFP|               45|\n",
      "|   CYS|               58|\n",
      "|   AKN|               63|\n",
      "|   BKG|               71|\n",
      "|   GST|               84|\n",
      "|   DLG|               84|\n",
      "|   HYA|               89|\n",
      "|   ADK|              104|\n",
      "|   OWB|              111|\n",
      "|   DRT|              114|\n",
      "|   PPG|              122|\n",
      "|   OGD|              126|\n",
      "|   OGS|              137|\n",
      "|   HGR|              138|\n",
      "|   STC|              145|\n",
      "|   MMH|              149|\n",
      "|   FLO|              170|\n",
      "|   SMX|              170|\n",
      "+------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group flights by ORIGIN  and rename count aggregation into number of flights\n",
    "grouped_flights = flights.groupby('ORIGIN').count().withColumnRenamed(\"count\",\"Number of flights\")\n",
    "#then the created dataframe sort it ascending\n",
    "grouped_flights.orderBy('Number of flights', ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[58.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the threshold. 1% quantile and store it to var ourliers.\n",
    "outliers = grouped_flights.approxQuantile(\"Number of flights\", [0.01], 0)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|ORIGIN|Number of flights|\n",
      "+------+-----------------+\n",
      "|   AKN|               63|\n",
      "|   BKG|               71|\n",
      "|   GST|               84|\n",
      "|   DLG|               84|\n",
      "|   HYA|               89|\n",
      "|   ADK|              104|\n",
      "|   OWB|              111|\n",
      "|   DRT|              114|\n",
      "|   PPG|              122|\n",
      "|   OGD|              126|\n",
      "|   OGS|              137|\n",
      "|   HGR|              138|\n",
      "|   STC|              145|\n",
      "|   MMH|              149|\n",
      "|   FLO|              170|\n",
      "|   SMX|              170|\n",
      "|   EAR|              200|\n",
      "|   GUC|              230|\n",
      "|   PRC|              236|\n",
      "|   WYS|              239|\n",
      "+------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop the ORIGIN who had <= 58 flights\n",
    "flights = flights.filter(\"`ORIGIN` != 'YNG'\")\n",
    "flights = flights.filter(\"`ORIGIN` != 'ART'\")\n",
    "flights = flights.filter(\"`ORIGIN` != 'IFP'\")\n",
    "flights = flights.filter(\"`ORIGIN` != 'CYS'\")\n",
    "\n",
    "# group flights by ORIGIN and rename count aggregation into number of flights\n",
    "grouped_flights = flights.groupby('ORIGIN').count().withColumnRenamed(\"count\",\"Number of flights\")\n",
    "#then the created dataframe sort it ascending\n",
    "grouped_flights.orderBy('Number of flights', ascending=True).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------+\n",
      "|ORIGIN|Number of delayed flights|\n",
      "+------+-------------------------+\n",
      "|   BGM|                      206|\n",
      "|   INL|                      111|\n",
      "|   PSE|                      256|\n",
      "|   DLG|                       28|\n",
      "|   MSY|                    20949|\n",
      "|   PPG|                       58|\n",
      "|   GEG|                     3226|\n",
      "|   DRT|                       30|\n",
      "|   BUR|                    10950|\n",
      "|   SNA|                    14002|\n",
      "|   GRB|                     1038|\n",
      "|   GTF|                      334|\n",
      "|   IDA|                      485|\n",
      "|   GRR|                     5152|\n",
      "|   LWB|                      186|\n",
      "|   JLN|                      211|\n",
      "|   PVU|                      202|\n",
      "|   PSG|                      125|\n",
      "|   EUG|                     1284|\n",
      "|   PVD|                     5614|\n",
      "+------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# those who had delay have DEP_DELAY >0. So with filter subset only them and keep it to another df named flights in ascending sort\n",
    "flights = flights.filter(\"`DEP_DELAY` > 0\").orderBy('DEP_DELAY', ascending=True)\n",
    "#enumerate delayed flights by Origin\n",
    "delayed_df = flights.groupby('ORIGIN').count().withColumnRenamed(\"count\",\"Number of delayed flights\")\n",
    "delayed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+-------------------------+\n",
      "|ORIGIN|Number of flights|Number of delayed flights|\n",
      "+------+-----------------+-------------------------+\n",
      "|   BGM|              920|                      206|\n",
      "|   DLG|               84|                       28|\n",
      "|   INL|              650|                      111|\n",
      "|   PSE|              792|                      256|\n",
      "|   MSY|            55883|                    20949|\n",
      "|   PPG|              122|                       58|\n",
      "|   DRT|              114|                       30|\n",
      "|   GEG|            12348|                     3226|\n",
      "|   BUR|            26583|                    10950|\n",
      "|   SNA|            41639|                    14002|\n",
      "|   GRB|             4846|                     1038|\n",
      "|   GTF|             1856|                      334|\n",
      "|   IDA|             2167|                      485|\n",
      "|   GRR|            17340|                     5152|\n",
      "|   LWB|              576|                      186|\n",
      "|   JLN|              805|                      211|\n",
      "|   PVU|              547|                      202|\n",
      "|   EUG|             4103|                     1284|\n",
      "|   PSG|              724|                      125|\n",
      "|   GSO|            12974|                     3651|\n",
      "+------+-----------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join the previous dataframes all flights(grouped_flights) and delayed flights (delayed_df) into one named all_misery\n",
    "all_misery = grouped_flights.join(delayed_df, \"ORIGIN\")\n",
    "all_misery.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+-------------------------+------------+\n",
      "|ORIGIN|Number of flights|Number of delayed flights|misery_index|\n",
      "+------+-----------------+-------------------------+------------+\n",
      "|   OGD|              126|                       83|       65.87|\n",
      "|   SCK|              747|                      486|       65.06|\n",
      "|   MDW|            87095|                    51131|       58.71|\n",
      "|   HYA|               89|                       52|       58.43|\n",
      "|   DAL|            70995|                    40544|       57.11|\n",
      "|   HOU|            57841|                    31438|       54.35|\n",
      "|   OWB|              111|                       56|       50.45|\n",
      "|   HGR|              138|                       68|       49.28|\n",
      "|   HTS|              879|                      423|       48.12|\n",
      "|   PPG|              122|                       58|       47.54|\n",
      "|   BQN|             1960|                      908|       46.33|\n",
      "|   TTN|             2603|                     1191|       45.75|\n",
      "|   MVY|              492|                      225|       45.73|\n",
      "|   STL|            66197|                    29854|        45.1|\n",
      "|   PSM|              303|                      134|       44.22|\n",
      "|   OAK|            52676|                    23154|       43.96|\n",
      "|   LCK|             1084|                      475|       43.82|\n",
      "|   BKG|               71|                       31|       43.66|\n",
      "|   BLV|             1019|                      437|       42.89|\n",
      "|   AKN|               63|                       27|       42.86|\n",
      "+------+-----------------+-------------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import format_number,round\n",
    "\n",
    "# create a new column with the misery index->  no_flights_delayed/ no_flights . Moreover cut some demical places for better visualization\n",
    "all_misery = all_misery.withColumn(\"misery_index\", lit(all_misery['Number of delayed flights']/all_misery['Number of flights']*100))\n",
    "#cut some demicals and keep only 2\n",
    "all_misery = all_misery.withColumn(\"misery_index\",round(all_misery['misery_index'],2))\n",
    "# order misery index in descending\n",
    "all_misery.orderBy('misery_index', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "After you have done that, go around your data again, but this time you will show the average and median delay for each airport. You may sort the results by either.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First we have to compute the median for each Origin and get them stored into a dataframe.\n",
    "* The next step is to compute the mean for each Origin and get them stored into another dataframe.\n",
    "* Finally join the above dataframes together and sort by median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------+\n",
      "|ORIGIN|Median of Departure Delay|\n",
      "+------+-------------------------+\n",
      "|   RDD|                     47.0|\n",
      "|   SAF|                     43.0|\n",
      "|   DVL|                     43.0|\n",
      "|   OTH|                     43.0|\n",
      "|   ERI|                     41.0|\n",
      "|   HVN|                     41.0|\n",
      "|   MMH|                     38.0|\n",
      "|   MKG|                     38.0|\n",
      "|   HYS|                     37.0|\n",
      "|   CMX|                     37.0|\n",
      "|   CKB|                     36.0|\n",
      "|   ASE|                     36.0|\n",
      "|   PAH|                     36.0|\n",
      "|   LWB|                     35.0|\n",
      "|   MEI|                     35.0|\n",
      "|   ORH|                     34.0|\n",
      "|   BKG|                     34.0|\n",
      "|   MBS|                     33.0|\n",
      "|   SCE|                     33.0|\n",
      "|   ACV|                     33.0|\n",
      "+------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "#window function that partition by ORIGIN\n",
    "delay_window = Window.partitionBy('ORIGIN')\n",
    "#store median as quantile (50%)\n",
    "median = F.expr('percentile_approx(DEP_DELAY, 0.5)')\n",
    "\n",
    "#group by Origin and find median - then rename column as Median of Departure Delay\n",
    "median_delay = flights.groupBy('ORIGIN').agg(median.alias('Median of Departure Delay'))\n",
    "# sort the dataframe in descending \n",
    "median_delay.orderBy('Median of Departure Delay', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------+\n",
      "|ORIGIN|Average Departure Delay|\n",
      "+------+-----------------------+\n",
      "|   DVL|                 138.42|\n",
      "|   PPG|                 106.45|\n",
      "|   JMS|                 104.86|\n",
      "|   CMX|                  99.82|\n",
      "|   RHI|                  96.75|\n",
      "|   LWB|                  95.56|\n",
      "|   SLN|                  94.35|\n",
      "|   SHD|                  89.89|\n",
      "|   CKB|                  88.91|\n",
      "|   ITH|                   88.4|\n",
      "|   SAF|                  86.85|\n",
      "|   EGE|                  85.35|\n",
      "|   EAU|                  85.29|\n",
      "|   HYS|                  84.97|\n",
      "|   LBL|                  84.57|\n",
      "|   ERI|                  84.28|\n",
      "|   LAR|                  83.41|\n",
      "|   PUB|                   83.1|\n",
      "|   PIB|                  82.32|\n",
      "|   MMH|                  81.98|\n",
      "+------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# group by Origin and compute the median\n",
    "meand = flights.groupby(['ORIGIN']).agg({'DEP_DELAY':'mean'})\n",
    "# rename the column appropriatelly\n",
    "mean_delay = meand.withColumnRenamed(\"avg(DEP_DELAY)\", \"Average Departure Delay\")\n",
    "# cut some demical we dont need\n",
    "mean_delay = mean_delay.withColumn(\"Average Departure Delay\",round(mean_delay['Average Departure Delay'],2))\n",
    "# sort them in descendign\n",
    "mean_delay.orderBy('Average Departure Delay', ascending=False).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------+-----------------------+\n",
      "|ORIGIN|Median of Departure Delay|Average Departure Delay|\n",
      "+------+-------------------------+-----------------------+\n",
      "|   RDD|                     47.0|                  76.08|\n",
      "|   OTH|                     43.0|                  78.13|\n",
      "|   DVL|                     43.0|                 138.42|\n",
      "|   SAF|                     43.0|                  86.85|\n",
      "|   HVN|                     41.0|                   65.4|\n",
      "|   ERI|                     41.0|                  84.28|\n",
      "|   MKG|                     38.0|                  67.45|\n",
      "|   MMH|                     38.0|                  81.98|\n",
      "|   CMX|                     37.0|                  99.82|\n",
      "|   HYS|                     37.0|                  84.97|\n",
      "|   ASE|                     36.0|                  74.03|\n",
      "|   CKB|                     36.0|                  88.91|\n",
      "|   PAH|                     36.0|                  68.91|\n",
      "|   LWB|                     35.0|                  95.56|\n",
      "|   MEI|                     35.0|                  72.12|\n",
      "|   BKG|                     34.0|                  48.55|\n",
      "|   ORH|                     34.0|                  66.35|\n",
      "|   SCE|                     33.0|                  73.93|\n",
      "|   ACV|                     33.0|                   63.7|\n",
      "|   MBS|                     33.0|                  79.53|\n",
      "+------+-------------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "#join together the above dataframes into a dataframe named airport_statistics\n",
    "airport_statistics = median_delay.join(mean_delay, \"ORIGIN\")\n",
    "\n",
    "#order by descending median\n",
    "airport_statistics.orderBy(\"Median of Departure Delay\",ascending=False).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Finally, enrich your airport misery index by tabulating both the probability, in descending order, that you will experience a delay at a given airport, and the average and median delay that you are likely to experience. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally join together all the dataframes into one named 'airport_statistics' which will have both the statistics and the misery index for each Airport in descending sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+-------------------------+------------+-------------------------+-----------------------+\n",
      "|ORIGIN|Number of flights|Number of delayed flights|misery_index|Median of Departure Delay|Average Departure Delay|\n",
      "+------+-----------------+-------------------------+------------+-------------------------+-----------------------+\n",
      "|   OGD|              126|                       83|       65.87|                     14.0|                   30.9|\n",
      "|   SCK|              747|                      486|       65.06|                     21.0|                  38.91|\n",
      "|   MDW|            87095|                    51131|       58.71|                     14.0|                  26.62|\n",
      "|   HYA|               89|                       52|       58.43|                     15.0|                  61.27|\n",
      "|   DAL|            70995|                    40544|       57.11|                     13.0|                  26.84|\n",
      "|   HOU|            57841|                    31438|       54.35|                     13.0|                  25.86|\n",
      "|   OWB|              111|                       56|       50.45|                     24.0|                   59.3|\n",
      "|   HGR|              138|                       68|       49.28|                     26.0|                  58.16|\n",
      "|   HTS|              879|                      423|       48.12|                     19.0|                  41.39|\n",
      "|   PPG|              122|                       58|       47.54|                     19.0|                 106.45|\n",
      "|   BQN|             1960|                      908|       46.33|                     21.0|                  42.71|\n",
      "|   TTN|             2603|                     1191|       45.75|                     31.0|                  61.29|\n",
      "|   MVY|              492|                      225|       45.73|                     16.0|                  48.84|\n",
      "|   STL|            66197|                    29854|        45.1|                     13.0|                  28.38|\n",
      "|   PSM|              303|                      134|       44.22|                     26.0|                  61.76|\n",
      "|   OAK|            52676|                    23154|       43.96|                     12.0|                  23.81|\n",
      "|   LCK|             1084|                      475|       43.82|                     22.0|                   54.3|\n",
      "|   BKG|               71|                       31|       43.66|                     34.0|                  48.55|\n",
      "|   BLV|             1019|                      437|       42.89|                     23.0|                  57.09|\n",
      "|   AKN|               63|                       27|       42.86|                     15.0|                  16.85|\n",
      "+------+-----------------+-------------------------+------------+-------------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#join misery_index dataframe and airport_statistics dataframe we have them all together.\n",
    "airport_delay_all = all_misery.join(airport_statistics, \"ORIGIN\").orderBy(\"misery_index\",ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Provide a \"misery index\" for airlines. That is, do the same thing you did for the airports, but this time we are interested in the airlines that make life difficult for passengers. Sort the airlines in descending order of probability that a flight operated by the airline has a delay. This time we do not care about outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer \n",
    "\n",
    "* Get the data again for the flights and the data for the airlines where we will get the description for the airline.\n",
    "* Now we don't care about outlier so we keep all the values.\n",
    "* Find the number of flights by Carrier and stored into a dataframe.\n",
    "* Find the number of delayed flights(those have departure_time >0) and stored into a dataframe by Airline (Carrier).\n",
    "* Join together the previous dataframes ( all flights - delayed flights) into a new dataframe.\n",
    "* Compute measury index as new column into the joined dataframe created above(all flights / delayed flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "# read flights file again \n",
    "flights = spark\\\n",
    "  .read\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .csv(\"515364771_T_ONTIME_REPORTING.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "#read the file with airlines details for future use at the end.\n",
    "airlines = spark\\\n",
    "  .read\\\n",
    "  .option(\"header\", \"true\")\\\n",
    "  .csv(\"Download_Lookup.asp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|CARRIER|Number of flights|\n",
      "+-------+-----------------+\n",
      "|     UA|           621565|\n",
      "|     NK|           176178|\n",
      "|     AA|           916818|\n",
      "|     EV|           202890|\n",
      "|     B6|           305010|\n",
      "|     DL|           949283|\n",
      "|     OO|           774137|\n",
      "|     F9|           120035|\n",
      "|     YV|           215138|\n",
      "|     MQ|           296001|\n",
      "|     OH|           278457|\n",
      "|     HA|            83723|\n",
      "|     G4|            96221|\n",
      "|     YX|           316090|\n",
      "|     AS|           245761|\n",
      "|     VX|            17670|\n",
      "|     WN|          1352552|\n",
      "|     9E|           245917|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#group carrier by number of flights\n",
    "carrier = flights.groupby('CARRIER').count().withColumnRenamed(\"count\",\"Number of flights\")\n",
    "carrier.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------+\n",
      "|CARRIER|Number of delayed flights|\n",
      "+-------+-------------------------+\n",
      "|     UA|                   185249|\n",
      "|     NK|                    51119|\n",
      "|     AA|                   317751|\n",
      "|     EV|                    53898|\n",
      "|     B6|                   125011|\n",
      "|     DL|                   286165|\n",
      "|     OO|                   203193|\n",
      "|     F9|                    53321|\n",
      "|     YV|                    60284|\n",
      "|     MQ|                    83546|\n",
      "|     OH|                   100247|\n",
      "|     HA|                    21767|\n",
      "|     G4|                    32886|\n",
      "|     YX|                    75839|\n",
      "|     AS|                    66254|\n",
      "|     VX|                     5382|\n",
      "|     WN|                   662363|\n",
      "|     9E|                    64942|\n",
      "+-------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter those flights have delay\n",
    "delayed_df_car = flights.filter(\"`DEP_DELAY` > 0\")\n",
    "# for those we have keeped , group by Carrier name and count them in a new column named no_flights_delayed\n",
    "delayed_carrier = delayed_df_car.groupby('CARRIER').count().withColumnRenamed(\"count\",\"Number of delayed flights\")\n",
    "delayed_carrier.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the above dataframes into a new named all_carriers\n",
    "all_carriers = carrier.join(delayed_carrier, \"CARRIER\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------------+------------+\n",
      "|CARRIER|Number of flights|Number of delayed flights|misery_index|\n",
      "+-------+-----------------+-------------------------+------------+\n",
      "|     WN|          1352552|                   662363|       48.97|\n",
      "|     F9|           120035|                    53321|       44.42|\n",
      "|     B6|           305010|                   125011|       40.99|\n",
      "|     OH|           278457|                   100247|        36.0|\n",
      "|     AA|           916818|                   317751|       34.66|\n",
      "|     G4|            96221|                    32886|       34.18|\n",
      "|     VX|            17670|                     5382|       30.46|\n",
      "|     DL|           949283|                   286165|       30.15|\n",
      "|     UA|           621565|                   185249|        29.8|\n",
      "|     NK|           176178|                    51119|       29.02|\n",
      "|     MQ|           296001|                    83546|       28.22|\n",
      "|     YV|           215138|                    60284|       28.02|\n",
      "|     AS|           245761|                    66254|       26.96|\n",
      "|     EV|           202890|                    53898|       26.57|\n",
      "|     9E|           245917|                    64942|       26.41|\n",
      "|     OO|           774137|                   203193|       26.25|\n",
      "|     HA|            83723|                    21767|        26.0|\n",
      "|     YX|           316090|                    75839|       23.99|\n",
      "+-------+-----------------+-------------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#compute in a new column (misery_index) the ration flights delayed/ all flights\n",
    "all_carriers_misery = all_carriers.withColumn(\"misery_index\", lit((all_carriers['Number of delayed flights']/all_carriers['Number of flights'])*100))\n",
    "# cut some demical we dont need\n",
    "all_carriers_misery = all_carriers_misery.withColumn(\"misery_index\",round(all_carriers_misery['misery_index'],2))\n",
    "# sort them descending\n",
    "all_carriers_misery.orderBy('misery_index', ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Then, go around your data again, but this time the criterion will be the average and median delay you may expect to have with an airline. Again we do not care about outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "* First we have to compute the median for each Carrier and get them stored into a dataframe.\n",
    "* The next step is to compute the mean for each Carrier and get them stored into another dataframe.\n",
    "* Finally join the above dataframes together and sort by median.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------+\n",
      "|CARRIER|Median of Departure Delay|\n",
      "+-------+-------------------------+\n",
      "|     EV|                     31.0|\n",
      "|     F9|                     25.0|\n",
      "|     YX|                     25.0|\n",
      "|     9E|                     25.0|\n",
      "|     B6|                     24.0|\n",
      "|     OO|                     24.0|\n",
      "|     YV|                     23.0|\n",
      "|     G4|                     22.0|\n",
      "|     UA|                     20.0|\n",
      "|     MQ|                     20.0|\n",
      "|     NK|                     19.0|\n",
      "|     VX|                     18.0|\n",
      "|     OH|                     17.0|\n",
      "|     AA|                     16.0|\n",
      "|     AS|                     14.0|\n",
      "|     DL|                     13.0|\n",
      "|     WN|                     12.0|\n",
      "|     HA|                      7.0|\n",
      "+-------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "#window function that partition by CARRIER\n",
    "delay_window = Window.partitionBy('CARRIER')\n",
    "#store median as quantile (50%)\n",
    "median = F.expr('percentile_approx(DEP_DELAY, 0.5)')\n",
    "#group by Carrier and find median\n",
    "median_delay = delayed_df_car.groupBy('CARRIER').agg(median.alias('Median of Departure Delay'))\n",
    "#then sort them by Descending\n",
    "median_delay.orderBy('Median of Departure Delay', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+\n",
      "|CARRIER|Average Departure Delay|\n",
      "+-------+-----------------------+\n",
      "|     EV|                  61.87|\n",
      "|     OO|                  54.69|\n",
      "|     9E|                  53.95|\n",
      "|     YV|                  51.56|\n",
      "|     F9|                  50.86|\n",
      "|     G4|                  49.59|\n",
      "|     B6|                  47.01|\n",
      "|     YX|                  46.78|\n",
      "|     NK|                  46.66|\n",
      "|     UA|                  45.34|\n",
      "|     OH|                  40.11|\n",
      "|     MQ|                  39.54|\n",
      "|     AA|                  37.12|\n",
      "|     VX|                  34.93|\n",
      "|     DL|                  33.57|\n",
      "|     AS|                  28.81|\n",
      "|     WN|                  25.38|\n",
      "|     HA|                  19.22|\n",
      "+-------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#find the mean for each Carrier \n",
    "meand = delayed_df_car.groupby(['CARRIER']).agg({'DEP_DELAY':'mean'})\n",
    "#the column contains the name rename it to Average Departure Delay\n",
    "mean_delay = meand.withColumnRenamed(\"avg(DEP_DELAY)\", \"Average Departure Delay\")\n",
    "# cut some demicals we don't need\n",
    "mean_delay = mean_delay.withColumn(\"Average Departure Delay\",round(mean_delay['Average Departure Delay'],2))\n",
    "#sort them in descending\n",
    "mean_delay.orderBy('avg(DEP_DELAY)', ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------+-----------------------+\n",
      "|CARRIER|Median of Departure Delay|Average Departure Delay|\n",
      "+-------+-------------------------+-----------------------+\n",
      "|     EV|                     31.0|                  61.87|\n",
      "|     F9|                     25.0|                  50.86|\n",
      "|     YX|                     25.0|                  46.78|\n",
      "|     9E|                     25.0|                  53.95|\n",
      "|     B6|                     24.0|                  47.01|\n",
      "|     OO|                     24.0|                  54.69|\n",
      "|     YV|                     23.0|                  51.56|\n",
      "|     G4|                     22.0|                  49.59|\n",
      "|     UA|                     20.0|                  45.34|\n",
      "|     MQ|                     20.0|                  39.54|\n",
      "|     NK|                     19.0|                  46.66|\n",
      "|     VX|                     18.0|                  34.93|\n",
      "|     OH|                     17.0|                  40.11|\n",
      "|     AA|                     16.0|                  37.12|\n",
      "|     AS|                     14.0|                  28.81|\n",
      "|     DL|                     13.0|                  33.57|\n",
      "|     WN|                     12.0|                  25.38|\n",
      "|     HA|                      7.0|                  19.22|\n",
      "+-------+-------------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#store them all together in a dataframe named airline_statistics\n",
    "airline_statistics = median_delay.join(mean_delay, \"CARRIER\")\n",
    "#and sort them in descending by median\n",
    "airline_statistics.orderBy(\"Median of Departure Delay\",ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "And finally, as you would expect,  enrich your airline misery index by tabulating both the probability, in descending order, that you will experience a delay flying with a particular airline, and the average and median delay that you are likely to experience.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "* First we have to join the dataframe with the misery index along with the one with the statistics into one named 'airline_delay_all'.\n",
    "* The next step is to join the additional dataset containing airline details.\n",
    "* To do so, we had to rename the column code into 'Carrier' to match column name from our dataset.\n",
    "* We also rename description to Airline name , for better visualization of info.\n",
    "* Joining two dataframes together we keep only Airline Name, misery_index , Median of Departure Delay, Average Departure Delay and we sort them by misery_index (probabilty of delay for each Airline).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join statistics and misery_index dataframes into one\n",
    "airline_delay_all = all_carriers_misery.join(airline_statistics, \"CARRIER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------------+------------+-------------------------+-----------------------+\n",
      "|CARRIER|Number of flights|Number of delayed flights|misery_index|Median of Departure Delay|Average Departure Delay|\n",
      "+-------+-----------------+-------------------------+------------+-------------------------+-----------------------+\n",
      "|     UA|           621565|                   185249|        29.8|                     20.0|                  45.34|\n",
      "|     NK|           176178|                    51119|       29.02|                     19.0|                  46.66|\n",
      "|     AA|           916818|                   317751|       34.66|                     16.0|                  37.12|\n",
      "|     EV|           202890|                    53898|       26.57|                     31.0|                  61.87|\n",
      "|     B6|           305010|                   125011|       40.99|                     24.0|                  47.01|\n",
      "|     DL|           949283|                   286165|       30.15|                     13.0|                  33.57|\n",
      "|     OO|           774137|                   203193|       26.25|                     24.0|                  54.69|\n",
      "|     F9|           120035|                    53321|       44.42|                     25.0|                  50.86|\n",
      "|     YV|           215138|                    60284|       28.02|                     23.0|                  51.56|\n",
      "|     MQ|           296001|                    83546|       28.22|                     20.0|                  39.54|\n",
      "|     OH|           278457|                   100247|        36.0|                     17.0|                  40.11|\n",
      "|     HA|            83723|                    21767|        26.0|                      7.0|                  19.22|\n",
      "|     G4|            96221|                    32886|       34.18|                     22.0|                  49.59|\n",
      "|     YX|           316090|                    75839|       23.99|                     25.0|                  46.78|\n",
      "|     AS|           245761|                    66254|       26.96|                     14.0|                  28.81|\n",
      "|     VX|            17670|                     5382|       30.46|                     18.0|                  34.93|\n",
      "|     WN|          1352552|                   662363|       48.97|                     12.0|                  25.38|\n",
      "|     9E|           245917|                    64942|       26.41|                     25.0|                  53.95|\n",
      "+-------+-----------------+-------------------------+------------+-------------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airline_delay_all.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renane column code to carrier to fit naming for the join with the additional dataframe\n",
    "airlines_renamed = airlines.withColumnRenamed(\"Code\", \"CARRIER\")\n",
    "#rename column description for better visualization\n",
    "airlines_renamed = airlines_renamed.withColumnRenamed(\"Description\", \"Airline Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|CARRIER|        Airline Name|\n",
      "+-------+--------------------+\n",
      "|    02Q|       Titan Airways|\n",
      "|    04Q|  Tradewind Aviation|\n",
      "|    05Q| Comlux Aviation, AG|\n",
      "|    06Q|Master Top Linhas...|\n",
      "|    07Q| Flair Airlines Ltd.|\n",
      "|    09Q|Swift Air, LLC d/...|\n",
      "|    0BQ|                 DCA|\n",
      "|    0CQ|ACM AIR CHARTER GmbH|\n",
      "|    0FQ|Maine Aviation Ai...|\n",
      "|    0GQ|Inter Island Airw...|\n",
      "|    0HQ|Polar Airlines de...|\n",
      "|     0J|          JetClub AG|\n",
      "|    0JQ|     Vision Airlines|\n",
      "|    0LQ|   Metropix UK, LLP.|\n",
      "|    0OQ|          Open Skies|\n",
      "|     0Q| Flying Service N.V.|\n",
      "|    0QQ|TAG Aviation (UK)...|\n",
      "|    0RQ|TAG Aviation Espa...|\n",
      "|    0TQ|  Corporatejets, XXI|\n",
      "|    0UQ|  Comlux Malta, Ltd.|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airlines_renamed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-------------------------+-----------------------+\n",
      "|        Airline Name|misery_index|Median of Departure Delay|Average Departure Delay|\n",
      "+--------------------+------------+-------------------------+-----------------------+\n",
      "|Southwest Airline...|       48.97|                     12.0|                  25.38|\n",
      "|Frontier Airlines...|       44.42|                     25.0|                  50.86|\n",
      "|     JetBlue Airways|       40.99|                     24.0|                  47.01|\n",
      "|   PSA Airlines Inc.|        36.0|                     17.0|                  40.11|\n",
      "|American Airlines...|       34.66|                     16.0|                  37.12|\n",
      "|       Allegiant Air|       34.18|                     22.0|                  49.59|\n",
      "|      Virgin America|       30.46|                     18.0|                  34.93|\n",
      "|Delta Air Lines Inc.|       30.15|                     13.0|                  33.57|\n",
      "|United Air Lines ...|        29.8|                     20.0|                  45.34|\n",
      "|    Spirit Air Lines|       29.02|                     19.0|                  46.66|\n",
      "|           Envoy Air|       28.22|                     20.0|                  39.54|\n",
      "|  Mesa Airlines Inc.|       28.02|                     23.0|                  51.56|\n",
      "|Alaska Airlines Inc.|       26.96|                     14.0|                  28.81|\n",
      "|ExpressJet Airlin...|       26.57|                     31.0|                  61.87|\n",
      "|   Endeavor Air Inc.|       26.41|                     25.0|                  53.95|\n",
      "|SkyWest Airlines ...|       26.25|                     24.0|                  54.69|\n",
      "|Hawaiian Airlines...|        26.0|                      7.0|                  19.22|\n",
      "|    Republic Airline|       23.99|                     25.0|                  46.78|\n",
      "+--------------------+------------+-------------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#join on common column CARRIER\n",
    "airlines_delay_all_info = airline_delay_all.join(airlines_renamed, \"CARRIER\")\n",
    "#drop Carrier , now we have airline name which is more clear\n",
    "airlines_delay_all_info = airlines_delay_all_info.drop('CARRIER')\n",
    "#select only these columns we need\n",
    "airlines_delay_all_info = airlines_delay_all_info.select(\"Airline Name\",\"misery_index\",\"Median of Departure Delay\",\"Average Departure Delay\")\n",
    "#sort by probability (misery_index) in descending \n",
    "airlines_delay_all_info.orderBy(\"misery_index\",ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
